{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bf9244-abef-4ccf-a870-ed452613a041",
   "metadata": {},
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58a4588-7a9f-4589-85f5-90036a3ee4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'John likes to watch movies. Mary likes movies too. \\\n",
    "Mary also likes to watch football games.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f830e3-1408-4002-bd2a-36f8b11cdd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'likes', 'to', 'watch', 'movies', 'Mary', 'likes', 'movies', 'too', 'Mary', 'also', 'likes', 'to', 'watch', 'football', 'games']\n"
     ]
    }
   ],
   "source": [
    "words = text.replace('.', '').split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0eb338e-4221-4cd3-a8bf-980fc040ba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['John', 'Mary', 'also', 'football', 'games', 'likes', 'movies',\n",
      "       'to', 'too', 'watch'], dtype='<U8'), array([1, 2, 1, 1, 1, 3, 2, 2, 1, 2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_count = np.unique(words, return_counts=True)\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66a1f66-a054-4da9-96bb-4941a6a37489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'John': 1, 'Mary': 2, 'also': 1, 'football': 1, 'games': 1, 'likes': 3, 'movies': 2, 'to': 2, 'too': 1, 'watch': 2}\n"
     ]
    }
   ],
   "source": [
    "word_to_cnt = {}\n",
    "for word, cnt in zip(*word_count):\n",
    "    word_to_cnt[word] = cnt\n",
    "print(word_to_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205697d-027a-4c9f-aa81-c37a6261c8cc",
   "metadata": {},
   "source": [
    "# Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7984140f-83a8-49c1-970d-061f7d4133fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'John likes to watch movies. Mary likes movies too.',\n",
    "    'Mary also likes to watch football games.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8b06bc-d142-4212-89d3-6d3b126dddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 2 1 2 1 1 1]\n",
      " [1 1 1 0 1 1 0 1 0 1]]\n",
      "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer()\n",
    "tdm_array = vector.fit_transform(corpus).toarray()\n",
    "tf_dic = vector.vocabulary_\n",
    "print(tdm_array)\n",
    "print(tf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a32a64-5be5-4564-a54c-13f2bc803df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   also  football  games  john  likes  mary  movies  to  too  watch\n",
      "0     0         0      0     1      2     1       2   1    1      1\n",
      "1     1         1      1     0      1     1       0   1    0      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tf_dic_sorted = dict(sorted(tf_dic.items(), key=lambda item: item[1]))\n",
    "tdm = pd.DataFrame(tdm_array, columns=tf_dic_sorted.keys())\n",
    "print(tdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279066f-b538-4cd9-84e2-59e258e2e909",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc5eb8c1-4ee6-4518-b704-da51f8e1ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       also  football     games      john     likes      mary    movies  \\\n",
      "0  0.000000  0.000000  0.000000  0.323699  0.460629  0.230315  0.647398   \n",
      "1  0.446101  0.446101  0.446101  0.000000  0.317404  0.317404  0.000000   \n",
      "\n",
      "         to       too     watch  \n",
      "0  0.230315  0.323699  0.230315  \n",
      "1  0.317404  0.000000  0.317404  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_array = tfidf_vec.fit_transform(corpus).toarray()\n",
    "tfidf_dic = tfidf_vec.vocabulary_\n",
    "tfidf_dic_sorted = dict(sorted(tfidf_dic.items(), key=lambda item: item[1]))\n",
    "\n",
    "tfidf_tdm = pd.DataFrame(tfidf_array, columns=tfidf_dic_sorted.keys()) #24쪽 코드 수정\n",
    "print(tfidf_tdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f42d0ea-65ea-4cfd-ac64-e505060861e1",
   "metadata": {},
   "source": [
    "# gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac8fdd2-2d70-4da5-8262-da3dcffac502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 0.21617142856121063), ('also', 0.09291722625494003), ('too', 0.027057476341724396), ('football', 0.016134677454829216), ('Mary', -0.010840574279427528), ('to', -0.02775036357343197), ('movies', -0.05234673246741295), ('games', -0.059876296669244766), ('watch', -0.111670583486557)]\n",
      "0.0640898\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'John likes to watch movies. Mary likes movies too.',\n",
    "    'Mary also likes to watch football games.'\n",
    "]\n",
    "\n",
    "word_list= []\n",
    "for word in corpus:\n",
    "    word_list.append(word.replace('.', '').split())\n",
    "\n",
    "# conda activate tf2.14\n",
    "# pip install gensim\n",
    "\n",
    "# ImportError: cannot import name 'triu' from 'scipy.linalg' 발생시\n",
    "# pip install scipy==1.12 (원래 버전 1.14.0)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(word_list, sg=0, vector_size=100, window=3, min_count=1)\n",
    "\n",
    "print(model.wv.most_similar('likes'))\n",
    "print(model.wv.similarity('movies', 'games'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bdbee-ca63-43f1-bdee-41d77f7c2ecc",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14347aca-574e-427d-842c-a28d14196ad4",
   "metadata": {},
   "source": [
    "### 1) 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4fa53f-c188-48fb-8a44-cae1a2dd430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               1280512   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1304110 (4.97 MB)\n",
      "Trainable params: 1304110 (4.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 참고자료\n",
    "# https://github.com/hjk7902/nlp/blob/main/1.%20DNN%20%EC%8B%A4%EC%8A%B5%20-%20%EB%A1%9C%EC%9D%B4%ED%84%B0%20%EA%B8%B0%EC%82%AC%20%EB%B6%84%EB%A5%98.ipynb\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(2500,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0, 5),\n",
    "    layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3651e961-a426-41ea-9da8-85f719bc77fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,) (2246,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=2500)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462d0495-f26e-4be3-8529-e93bcfcef39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0]) # 숫자로 매핑되어있음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628bc49a-f540-4a30-bf9f-64a3f54952cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5485dd5b-a1b8-41e3-b49d-34d5eacfbefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cocoa', 'grain', 'veg-oil', 'earn', 'acq', 'wheat', 'copper', 'housing', 'money-supply', 'coffee', 'sugar', 'trade', 'reserves', 'ship', 'cotton', 'carcass', 'crude', 'nat-gas', 'cpi', 'money-fx', 'interest', 'gnp', 'meal-feed', 'alum', 'oilseed', 'gold', 'tin', 'strategic-metal', 'livestock', 'retail', 'ipi', 'iron-steel', 'rubber', 'heat', 'jobs', 'lei', 'bop', 'zinc', 'orange', 'pet-chem', 'dlr', 'gas', 'silver', 'wpi', 'hog', 'lead')\n"
     ]
    }
   ],
   "source": [
    "labels = reuters.get_label_names()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb86d1e6-4478-4a41-9326-edf016146460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127ff2c5-a339-45d3-8ea8-064042ed1fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 56)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0]), len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d189419d-59a3-4905-bc93-6c39692fef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer(num_words=2500)\n",
    "X_train_tok = tok.sequences_to_matrix(X_train, mode='count')\n",
    "X_test_tok = tok.sequences_to_matrix(X_test, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a5d6561-11a1-40b3-922f-e359164850f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (8982, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tok), X_train_tok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e9b3dc7-20fb-4386-91a4-9db356ce3cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 4. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tok[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a156c64-7ba1-4708-8f6e-b36c68afeb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 [==============================] - 2s 10ms/step - loss: 1.3347 - accuracy: 0.7420\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.5523 - accuracy: 0.8796\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.3572 - accuracy: 0.9207\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.2733 - accuracy: 0.9373\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.2427 - accuracy: 0.9443\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.2040 - accuracy: 0.9489\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1923 - accuracy: 0.9509\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1777 - accuracy: 0.9526\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9517\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1600 - accuracy: 0.9517\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9530\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1461 - accuracy: 0.9535\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1405 - accuracy: 0.9525\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1351 - accuracy: 0.9530\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1287 - accuracy: 0.9532\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1303 - accuracy: 0.9507\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1230 - accuracy: 0.9523\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1224 - accuracy: 0.9525\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1188 - accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.1145 - accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25a70e13b90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tok, y_train, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ff4809d-027e-4dca-8397-3e91c62f9250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 1.1148 - accuracy: 0.7992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1147968769073486, 0.799198567867279]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_tok, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63daad96-27a0-4460-b746-f504f3e0143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2500)\n"
     ]
    }
   ],
   "source": [
    "sample = X_train_tok[333].reshape(-1, 2500)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b976e06b-9e51-42e3-ac58-0f9faff5fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[6.29868955e-05 8.33811995e-04 2.01068015e-05 9.85312402e-01\n",
      "  2.30382429e-03 1.93045344e-05 1.05868939e-05 1.86735542e-05\n",
      "  3.47305904e-04 4.90160892e-04 4.26667102e-04 1.20029994e-03\n",
      "  3.11418611e-04 1.16212483e-04 1.56585666e-05 7.86202872e-06\n",
      "  4.21627919e-04 7.90592367e-06 5.37756059e-05 4.65283031e-03\n",
      "  1.23642269e-03 1.00586760e-04 9.21211540e-06 7.21404940e-05\n",
      "  7.26803701e-05 4.48649189e-05 4.36036862e-06 2.08681945e-06\n",
      "  5.08273894e-04 1.12201988e-05 1.16126736e-04 8.62091747e-06\n",
      "  9.86109444e-05 1.84067380e-06 7.66225567e-05 9.49348851e-06\n",
      "  7.22183497e-04 1.89901002e-05 1.41779732e-04 9.02555894e-06\n",
      "  5.53047030e-05 7.00668488e-06 5.55707675e-06 1.49424186e-05\n",
      "  5.86144915e-06 1.26884352e-05]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(sample)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da3d420-0278-4125-a57a-df6a15454713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8514e60-1fd2-44a2-a330-39a9e17ac215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[333]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a40208-af43-4966-9eac-9ba1b3996376",
   "metadata": {},
   "source": [
    "### 2)\n",
    "### 인공신경망의 기본 이론을 알고 있으면 어떤 모델을 사용하더라도\n",
    "### 입력과 출력의 shape만 맞춰주면 학습은 된다는 것을 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6615ee0d-0466-447f-ab78-7fee8cf565ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 24, 24, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 11, 11, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4007854 (15.29 MB)\n",
      "Trainable params: 4007854 (15.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=(50,50,1), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44c1da99-7cc1-4450-b25e-dcb73589e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0d99924-836d-44bb-b16e-0c2d39252c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer(num_words=2500)\n",
    "X_train_tok = tok.sequences_to_matrix(X_train, mode='count')\n",
    "X_test_tok = tok.sequences_to_matrix(X_test, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "667300dd-25ba-4451-a299-a8c790179ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok = X_train_tok.reshape(-1, 50, 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "695bde28-bcbf-4f36-ae99-db0d0e1734dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 [==============================] - 10s 67ms/step - loss: 1.8895 - accuracy: 0.5501\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 10s 69ms/step - loss: 1.0819 - accuracy: 0.7407\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.7881 - accuracy: 0.8062\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.6114 - accuracy: 0.8483\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.4853 - accuracy: 0.8749\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.3945 - accuracy: 0.8977\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.3329 - accuracy: 0.9132\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 10s 69ms/step - loss: 0.2918 - accuracy: 0.9212\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.2640 - accuracy: 0.9330\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 10s 67ms/step - loss: 0.2473 - accuracy: 0.9379\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.2330 - accuracy: 0.9414\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 10s 67ms/step - loss: 0.2228 - accuracy: 0.9426\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.2085 - accuracy: 0.9466\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 10s 67ms/step - loss: 0.2037 - accuracy: 0.9467\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 10s 69ms/step - loss: 0.1895 - accuracy: 0.9496\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.1897 - accuracy: 0.9475\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 10s 68ms/step - loss: 0.1741 - accuracy: 0.9517\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 9s 67ms/step - loss: 0.1765 - accuracy: 0.9521\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 9s 66ms/step - loss: 0.1691 - accuracy: 0.9508\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 9s 67ms/step - loss: 0.1663 - accuracy: 0.9526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25a6e7d0210>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tok, y_train, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e6936a3-5f5c-4536-bad5-fbd7b61ebb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "sample = X_train_tok[333].reshape(-1, 50, 50, 1)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b03ba3a-455f-4145-aa2f-4d610e60726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(sample)\n",
    "\n",
    "import numpy as np\n",
    "print(np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c71d6-0870-4678-bec3-575f72b85885",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e223a489-ecce-48fe-bbf1-570ea2ecbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18c57be2-0ec9-47ed-b2c3-78d3a7e2e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN의 입력으로\n",
    "# 입력 데이터(텍스트를 숫자로 매핑한 데이터)를 DTM 행렬을 만들어 입력\n",
    "# 입력 데이터를 같은 길이의 데이터로 자르거나 채워서 입력, 내부적으로 임베딩을 하도록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a9e6e74-7d87-453a-b94c-d25f78c97274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 80, 32)            320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 326338 (1.24 MB)\n",
      "Trainable params: 326338 (1.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32),\n",
    "    layers.SimpleRNN(64),\n",
    "    layers.Dense(2, activation='softmax') # Loss = 'sparse_categorical_crossentropy'\n",
    "    # layers.Dense(2, activation='sigmoid') # Loss = 'binary_crossentropy'\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754279cb-314a-478a-8cbb-cd72354dbd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
